{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Conditional_Gan.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0438759c294d48ac8ba1c9cf1ea9ebb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff3c4d8c027f47c3b5da0f7b7e07bb28","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_276ff854e9a64835aa78d98b266f00a3","IPY_MODEL_54d9ca56e8bf425dadfdde77805288f2"]}},"ff3c4d8c027f47c3b5da0f7b7e07bb28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"276ff854e9a64835aa78d98b266f00a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d536cd34dfde41c59c539cc157642cdf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e9653fbb1714cad8e8ff4da4bb7b6fe"}},"54d9ca56e8bf425dadfdde77805288f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_65bea8d0bc94412c954ec029570d792b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 109237/? [00:05&lt;00:00, 20329.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98c3dfcb921b4963ac1169e70a249f77"}},"d536cd34dfde41c59c539cc157642cdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e9653fbb1714cad8e8ff4da4bb7b6fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65bea8d0bc94412c954ec029570d792b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"98c3dfcb921b4963ac1169e70a249f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c6951a1964b408ab9d8a41e70f7d7d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0aa31adddf9413eb61e07b020643d85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_738329eb01cf4c6aba888bd44a6ecbb4","IPY_MODEL_f7b65ecdc4094026a9a6fe9e08ea062f"]}},"c0aa31adddf9413eb61e07b020643d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"738329eb01cf4c6aba888bd44a6ecbb4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e2c32a56201e42f88ca6091d06e0b95a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_00a4d4af41e44688bf156f143866f500"}},"f7b65ecdc4094026a9a6fe9e08ea062f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f45edd9fed1c4d5d8a0c243640460dde","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/? [36:27&lt;00:00, 2187.24s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b1b8c70c91740f9a769eb7f6ed0b82d"}},"e2c32a56201e42f88ca6091d06e0b95a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"00a4d4af41e44688bf156f143866f500":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f45edd9fed1c4d5d8a0c243640460dde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6b1b8c70c91740f9a769eb7f6ed0b82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a4c8115fd90439285be3cbf1e425a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_53fa120c7ece401da1d5c6882774a036","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_620bb52d22db4c23a525557811d0fa39","IPY_MODEL_b81dfa380d7c480480b1ea601f0dde31"]}},"53fa120c7ece401da1d5c6882774a036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"620bb52d22db4c23a525557811d0fa39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bef35199d9bd4c7ea302f55a3d404d24","_dom_classes":[],"description":" 89%","_model_name":"FloatProgressModel","bar_style":"","max":854,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":763,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f97c4f5ba1d24dc3a4e729a888b4a2c1"}},"b81dfa380d7c480480b1ea601f0dde31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ff0ad1bd826e410aab8b61f7a140e586","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 763/854 [1:46:32&lt;14:14,  9.39s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c94e43b129a4efd9f66a74d5e3474ef"}},"bef35199d9bd4c7ea302f55a3d404d24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f97c4f5ba1d24dc3a4e729a888b4a2c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff0ad1bd826e410aab8b61f7a140e586":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c94e43b129a4efd9f66a74d5e3474ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GuGcmDFyUQ0E"},"source":["# PyTorch for GANs Workshop Part 1\n","\n","This notebook implements a simple GAN training pipeline which can easily be adapted for your projects. Components of a typical GAN training pipeline include:\n","\n","*   Custom Dataset Class + Dataloader\n","*   Generator\n","*   Discriminator\n","*   Optimizer + Scheduler\n","*   Loss Functions\n","*   Training Loop\n","*   Loading and Saving Checkpoints\n","\n","This notebook implements DCGAN for simplicity but feel free to swap out the archtecture for newer and better models."]},{"cell_type":"code","metadata":{"id":"r40GkIWNx9n-","executionInfo":{"status":"ok","timestamp":1614406764414,"user_tz":480,"elapsed":344,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["# TOTAL_CLASSES = 1103\n","TOTAL_CLASSES = 1103 #reducing the number of labels to 398 (only culture tags)\n","\n","DATA_PATH_SMALL = \"drive/MyDrive/CS236G/data-sample/\"\n","DATA_PATH_BIG = \"drive/MyDrive/CS236G/data-big/\"\n","device = 'cuda'\n","z_dim = 64 #noise vector dimension\n","\n","image_resize = 10\n","postcard_shape = (3, image_resize, image_resize) \n","n_classes = TOTAL_CLASSES\n","batch_size =128\n","\n","criterion = nn.BCEWithLogitsLoss()\n","n_epochs = 10\n","display_step = 20\n","batch_size = 128\n","lr = 0.0002\n","device = 'cuda'\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_TTf83rwlma","executionInfo":{"status":"ok","timestamp":1614404773771,"user_tz":480,"elapsed":17475,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"c2f3559c-b4ff-4649-b7c8-077e6364326a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1I9bLCSJwnP7","executionInfo":{"status":"ok","timestamp":1614405752489,"user_tz":480,"elapsed":809,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["import torch\n","from torch import nn\n","from tqdm.auto import tqdm\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torchvision.utils import make_grid\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import torch.utils.data as data\n","import os\n","torch.manual_seed(0) # Set for our testing purposes, please do not change!\n","from PIL import Image\n","import csv\n","\n","\n","\n","def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n","    '''\n","    Function for visualizing images: Given a tensor of images, number of images, and\n","    size per image, plots and prints the images in an uniform grid.\n","    '''\n","    image_tensor = (image_tensor + 1) / 2\n","    image_unflat = image_tensor.detach().cpu()\n","    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n","    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n","    if show:\n","        plt.show()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIcm6aKsyd_y"},"source":["# Generator\n","\n","> Indented block\n","\n"]},{"cell_type":"code","metadata":{"id":"lytJLHNYw0Gz","executionInfo":{"status":"ok","timestamp":1614405754444,"user_tz":480,"elapsed":276,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["class MyConvTranspose2d(nn.Module):\n","    def __init__(self, conv, output_size):\n","        super(MyConvTranspose2d, self).__init__()\n","        self.output_size = output_size\n","        self.conv = conv\n","        \n","    def forward(self, x):\n","        x = self.conv(x, output_size=self.output_size)\n","        return x\n","\n","class Generator(nn.Module):\n","    '''\n","    Generator Class\n","    Values:\n","        input_dim: the dimension of the input vector, a scalar\n","        im_chan: the number of channels in the images, fitted for the dataset used, a scalar\n","              (MNIST is black-and-white, so 1 channel is your default)\n","        hidden_dim: the inner dimension, a scalar\n","    '''\n","    def __init__(self, input_dim=10, im_chan=3, hidden_dim=64): #changing im_chan\n","        super(Generator, self).__init__()\n","        self.input_dim = input_dim\n","        # Build the neural network\n","        self.gen = nn.Sequential(\n","            self.make_gen_block(input_dim, hidden_dim * 4),\n","            # self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=6, stride=1, final_layer=True)\n","            self.make_gen_block(hidden_dim * 4, im_chan, kernel_size=6, stride=1, final_layer=True)\n","            # self.make_gen_block(hidden_dim * 2, hidden_dim),\n","            # self.make_gen_block(hidden_dim, im_chan, kernel_size=4, stride=4, final_layer=True)\n","        ) \n","\n","    def make_gen_block(self, input_channels, output_channels, kernel_size=5, stride=5, final_layer=False):\n","        '''\n","        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n","        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n","        Parameters:\n","            input_channels: how many channels the input feature representation has\n","            output_channels: how many channels the output feature representation should have\n","            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n","            stride: the stride of the convolution\n","            final_layer: a boolean, true if it is the final layer and false otherwise \n","                      (affects activation and batchnorm)\n","        '''\n","        if not final_layer:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n","                nn.BatchNorm2d(output_channels),\n","                nn.ReLU(inplace=True),\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n","                nn.Tanh(),\n","            )\n","\n","    def forward(self, noise):\n","        '''\n","        Function for completing a forward pass of the generator: Given a noise tensor, \n","        returns generated images.\n","        Parameters:\n","            noise: a noise tensor with dimensions (n_samples, input_dim)\n","        '''\n","        x = noise.view(len(noise), self.input_dim, 1, 1)\n","        return self.gen(x)\n","\n","def get_noise(n_samples, input_dim, device='cpu'):\n","    '''\n","    Function for creating noise vectors: Given the dimensions (n_samples, input_dim)\n","    creates a tensor of that shape filled with random numbers from the normal distribution.\n","    Parameters:\n","        n_samples: the number of samples to generate, a scalar\n","        input_dim: the dimension of the input vector, a scalar\n","        device: the device type\n","    '''\n","    return torch.randn(n_samples, input_dim, device=device)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"zz78pQgBKTbu","executionInfo":{"status":"error","timestamp":1614388950340,"user_tz":480,"elapsed":10379,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"49bd89c1-2b4e-4db2-bf3c-360784aabfdd"},"source":["temp_noise = torch.rand((1,1167)).to(device)\n","fake_ = gen(temp_noise)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-6cc1baa9ec23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1167\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfake_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"1AGStq0mKcy1","executionInfo":{"status":"error","timestamp":1614388953468,"user_tz":480,"elapsed":268,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"d2841719-05c0-4df4-ce22-2b1f007751bb"},"source":["fake_.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-a054f7c7cfe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'fake_' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"MtzevAHoygtl"},"source":["# Discriminator"]},{"cell_type":"code","metadata":{"id":"TF6SjZHrxCo9","executionInfo":{"status":"ok","timestamp":1614405756957,"user_tz":480,"elapsed":279,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["class Discriminator(nn.Module):\n","    '''\n","    Discriminator Class\n","    Values:\n","      im_chan: the number of channels in the images, fitted for the dataset used, a scalar\n","            (MNIST is black-and-white, so 1 channel is your default)\n","      hidden_dim: the inner dimension, a scalar\n","    '''\n","    def __init__(self, im_chan=3, hidden_dim=64): #changing im_chan\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            self.make_disc_block(im_chan, hidden_dim),\n","            self.make_disc_block(hidden_dim, hidden_dim * 2),\n","            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n","        )\n","\n","    def make_disc_block(self, input_channels, output_channels, kernel_size=2, stride=2, final_layer=False):\n","        '''\n","        Function to return a sequence of operations corresponding to a discriminator block of the DCGAN; \n","        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).\n","        Parameters:\n","            input_channels: how many channels the input feature representation has\n","            output_channels: how many channels the output feature representation should have\n","            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n","            stride: the stride of the convolution\n","            final_layer: a boolean, true if it is the final layer and false otherwise \n","                      (affects activation and batchnorm)\n","        '''\n","        if not final_layer:\n","            return nn.Sequential(\n","                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n","                nn.BatchNorm2d(output_channels),\n","                nn.LeakyReLU(0.2, inplace=True),\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n","            )\n","\n","    def forward(self, image):\n","        '''\n","        Function for completing a forward pass of the discriminator: Given an image tensor, \n","        returns a 1-dimension tensor representing fake/real.\n","        Parameters:\n","            image: a flattened image tensor with dimension (im_chan)\n","        '''\n","        disc_pred = self.disc(image)\n","        return disc_pred.view(len(disc_pred), -1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDBGur-eNf5u"},"source":["disc = Discriminator(im_chan=discriminator_im_chan).to(device)\n","temp_ = torch.rand((20, 3312, 10, 10)).to(device)\n","output = disc(temp_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZ4kBmcpyjMP"},"source":["#Class Input : We will replace this with description embeddings\n","\n","In conditional GANs, the input vector for the generator will also need to include the class information. The class is represented using a one-hot encoded vector where its length is the number of classes and each index represents a class. The vector is all 0's and a 1 on the chosen class."]},{"cell_type":"code","metadata":{"id":"jZF2Irc1yXwD","executionInfo":{"status":"ok","timestamp":1614405759508,"user_tz":480,"elapsed":376,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["import torch.nn.functional as F\n","def get_one_hot_labels(labels, n_classes):\n","    '''\n","    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\n","    Parameters:\n","        labels: tensor of labels from the dataloader, size (?)\n","        n_classes: the total number of classes in the dataset, an integer scalar\n","    '''\n","    #### START CODE HERE ####\n","    return nn.functional.one_hot(labels, n_classes) \n","    #### END CODE HERE ####"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6mE-s-dLzvpa"},"source":["# Combine vectors"]},{"cell_type":"code","metadata":{"id":"jYJmK1n5ythT","executionInfo":{"status":"ok","timestamp":1614405759873,"user_tz":480,"elapsed":322,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["def combine_vectors(x, y):\n","    '''\n","    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\n","    Parameters:\n","      x: (n_samples, ?) the first vector. \n","        In this assignment, this will be the noise vector of shape (n_samples, z_dim), \n","        but you shouldn't need to know the second dimension's size.\n","      y: (n_samples, ?) the second vector.\n","        Once again, in this assignment this will be the one-hot class vector \n","        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.\n","    '''\n","    # Note: Make sure this function outputs a float no matter what inputs it receives\n","    #### START CODE HERE ####\n","#     print(x.shape, y.shape)\n","    combined = torch.cat((x.float(),y.float()),dim=1)\n","    #### END CODE HERE ####\n","    return combined"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTfIEix01BXC"},"source":["# Dataset transformations and Hyperparams\n","We will replace n_classes with embedding size => n_dim"]},{"cell_type":"code","metadata":{"id":"ZIK59peV0JAz","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0438759c294d48ac8ba1c9cf1ea9ebb9","ff3c4d8c027f47c3b5da0f7b7e07bb28","276ff854e9a64835aa78d98b266f00a3","54d9ca56e8bf425dadfdde77805288f2","d536cd34dfde41c59c539cc157642cdf","5e9653fbb1714cad8e8ff4da4bb7b6fe","65bea8d0bc94412c954ec029570d792b","98c3dfcb921b4963ac1169e70a249f77","9c6951a1964b408ab9d8a41e70f7d7d9","c0aa31adddf9413eb61e07b020643d85","738329eb01cf4c6aba888bd44a6ecbb4","f7b65ecdc4094026a9a6fe9e08ea062f","e2c32a56201e42f88ca6091d06e0b95a","00a4d4af41e44688bf156f143866f500","f45edd9fed1c4d5d8a0c243640460dde","6b1b8c70c91740f9a769eb7f6ed0b82d"]},"executionInfo":{"status":"ok","timestamp":1614406462486,"user_tz":480,"elapsed":11390,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"61a0c2ae-12c4-4b3e-8660-cb26172ab024"},"source":["\n","\n","class Dataset(data.Dataset):\n","    \"\"\"Dataset class for dsprites\"\"\"\n","\n","    def __init__(self, data_root, normalize=True, rotate=False):\n","        \n","        \n","        #get the data labels\n","        self.img_to_labels = {}\n","        with open(DATA_PATH_BIG+'train.csv') as csv_file:\n","            csv_reader = csv.reader(csv_file, delimiter=',')\n","            next(csv_reader) # skips the first row containing the row names\n","            for row in tqdm(csv_reader):\n","              classes = row[1].split()\n","              classes = [int(e) for e in classes]\n","              self.img_to_labels[str(row[0])] = classes\n","\n","        # Recursively exract paths to all .png files in subdirectories\n","        self.file_paths = []\n","        self.file_names = []\n","        for path, subdirs, files in tqdm(os.walk(data_root)):\n","            for name in files:\n","                plain_name = name.split('.')[0]\n","\n","                if name.endswith(\".png\") and plain_name in self.img_to_labels:\n","                    \n","                    # print('here')\n","                    # Way 1\n","                    # condition = True\n","                    # for class_ in self.img_to_labels[plain_name]:\n","                    #     if class_ >= TOTAL_CLASSES:\n","                    #         condition = False\n","                    #         break\n","\n","                    # Way 2\n","                    condition = True\n","                    labels = self.img_to_labels[plain_name]\n","                    filtered_labels = [e for e in labels if e < TOTAL_CLASSES]\n","                    if len(filtered_labels) == 0:\n","                        condition = False\n","\n","                    if condition:\n","                      self.file_paths.append(os.path.join(path, name))\n","                      name = plain_name\n","                      self.file_names.append(name)\n","            # break\n","        self.transform = self._set_transforms(normalize, rotate)\n","\n","\n","    def _set_transforms(self, normalize, rotate):\n","        \"\"\"Decide transformations to data to be applied\"\"\"\n","\n","        transform = transforms.Compose([\n","                    transforms.Resize((image_resize,image_resize)),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize((0.5,), (0.5,)),\n","                    ])\n","        return transform\n","\n","    def __len__(self):\n","        \"\"\"Required: specify dataset length for dataloader\"\"\"\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, index):\n","        \"\"\"Required: specify what each iteration in dataloader yields\"\"\"\n","        img = Image.open(self.file_paths[index])\n","        img = self.transform(img)\n","        one_hot = torch.zeros(n_classes, dtype=int)\n","        classes = self.img_to_labels[self.file_names[index]]\n","\n","        for class_ in classes:\n","          one_hot[class_]=1\n","        \n","        return img,one_hot\n","\n","\n","# dataset = Dataset(data_root=DATA_PATH_SMALL+'train/')\n","\n","#loading the bigger dataset\n","dataset = Dataset(data_root=DATA_PATH_BIG+'train/')\n","\n","dataloader = data.DataLoader(dataset,\n","                             batch_size=batch_size,\n","                             num_workers=4,\n","                             shuffle=True)"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0438759c294d48ac8ba1c9cf1ea9ebb9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c6951a1964b408ab9d8a41e70f7d7d9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","here\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ba3vB9p9C3-K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDp5Tykc2RwB"},"source":["#testing if dataloader works\n","for real,labels in tqdm(dataloader):\n","  cur_batch_size = len(real)\n","  real = real.to(device='cpu')\n","  print(real.shape) #currently have 101 images\n","  print('hi')\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJM0TbHS9njA","executionInfo":{"status":"ok","timestamp":1614406636639,"user_tz":480,"elapsed":643,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"37078327-34f2-43d0-f661-765c78c3e4ec"},"source":["labels.shape"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 1103])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"3TSnitAC5YeQ"},"source":["# Initializing input dimensions and weights"]},{"cell_type":"code","metadata":{"id":"94i_fmCa3paU","executionInfo":{"status":"ok","timestamp":1614406638302,"user_tz":480,"elapsed":406,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["def get_input_dimensions(z_dim, postcard_shape, n_classes):\n","    '''\n","    Function for getting the size of the conditional input dimensions \n","    from z_dim, the image shape, and number of classes.\n","    Parameters:\n","        z_dim: the dimension of the noise vector, a scalar\n","        postcard_shape: the shape of each postcard image as (C, W, H), which is (3, 200, 200)\n","        n_classes: the total number of classes in the dataset, an integer scalar\n","                (10 for MNIST)\n","    Returns: \n","        generator_input_dim: the input dimensionality of the conditional generator, \n","                          which takes the noise and class vectors\n","        discriminator_im_chan: the number of input channels to the discriminator\n","                            (e.g. C x 200 x 200 for postcard)\n","    '''\n","    #### START CODE HERE ####\n","    generator_input_dim = z_dim+n_classes\n","    discriminator_im_chan = postcard_shape[0]*(n_classes+1)\n","    # discriminator_im_chan = postcard_shape[0]+n_classes\n","\n","    #### END CODE HERE ####\n","    return generator_input_dim, discriminator_im_chan"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGimoCXC8Osq","executionInfo":{"status":"ok","timestamp":1614406737138,"user_tz":480,"elapsed":276,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}}},"source":["generator_input_dim, discriminator_im_chan = get_input_dimensions(z_dim, postcard_shape, n_classes)\n","\n","gen = Generator(input_dim=generator_input_dim).to(device)\n","gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n","disc = Discriminator(im_chan=discriminator_im_chan).to(device)\n","disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","    if isinstance(m, nn.BatchNorm2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","        torch.nn.init.constant_(m.bias, 0)\n","gen = gen.apply(weights_init)\n","disc = disc.apply(weights_init)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJSwnPVwNTE3","executionInfo":{"status":"ok","timestamp":1614406739981,"user_tz":480,"elapsed":463,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"a4977157-f6e3-4dc3-8f94-1ec4d1362a62"},"source":["discriminator_im_chan"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3312"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5a4c8115fd90439285be3cbf1e425a0b","53fa120c7ece401da1d5c6882774a036","620bb52d22db4c23a525557811d0fa39","b81dfa380d7c480480b1ea601f0dde31","bef35199d9bd4c7ea302f55a3d404d24","f97c4f5ba1d24dc3a4e729a888b4a2c1","ff0ad1bd826e410aab8b61f7a140e586","3c94e43b129a4efd9f66a74d5e3474ef"],"output_embedded_package_id":"16U1ZAhB6QosGqI-ajSOPQEz_1metr4dG"},"id":"85HY7GqY8TdV","outputId":"3977b587-4d1d-41be-cc59-2afbd4dd0d10"},"source":["\n","cur_step = 0\n","generator_losses = []\n","discriminator_losses = []\n","\n","#UNIT TEST NOTE: Initializations needed for grading\n","noise_and_labels = False\n","fake = False\n","\n","fake_image_and_labels = False\n","real_image_and_labels = False\n","disc_fake_pred = False\n","disc_real_pred = False\n","\n","\n","for epoch in range(n_epochs):\n","    # Dataloader returns the batches and the labels\n","    for real, labels in tqdm(dataloader):\n","\n","        cur_batch_size = len(real)\n","        # Flatten the batch of real images from the dataset\n","        real = real.to(device)\n","        # one_hot_labels = get_one_hot_labels(labels.to(device), n_classes)\n","        one_hot_labels = labels.to(device)\n","        image_one_hot_labels = one_hot_labels[:, :, None, None]\n","        image_one_hot_labels = image_one_hot_labels.repeat(1, postcard_shape[0], postcard_shape[1], postcard_shape[2])\n","        # image_one_hot_labels = image_one_hot_labels.repeat(1, postcard_shape[0], 28, 28) #ToDo \n","\n","        ### Update discriminator ###\n","        # Zero out the discriminator gradients\n","        disc_opt.zero_grad()\n","        # Get noise corresponding to the current batch_size \n","        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n","        \n","        # Now you can get the images from the generator\n","        # Steps: 1) Combine the noise vectors and the one-hot labels for the generator\n","        #        2) Generate the conditioned fake images\n","       \n","        #### START CODE HERE ####\n","        noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n","        fake = gen(noise_and_labels)\n","\n","        #### END CODE HERE ####\n","        \n","        # Make sure that enough images were generated\n","        assert len(fake) == len(real)\n","        # Check that correct tensors were combined\n","        assert tuple(noise_and_labels.shape) == (cur_batch_size, fake_noise.shape[1] + one_hot_labels.shape[1])\n","        # It comes from the correct generator\n","        assert tuple(fake.shape) == (len(real), 3, image_resize, image_resize) #ToDo: check the fake image size\n","        # Now you can get the predictions from the discriminator\n","        # Steps: 1) Create the input for the discriminator\n","        #           a) Combine the fake images with image_one_hot_labels, \n","        #              remember to detach the generator (.detach()) so you do not backpropagate through it\n","        #           b) Combine the real images with image_one_hot_labels\n","        #        2) Get the discriminator's prediction on the fakes as disc_fake_pred\n","        #        3) Get the discriminator's prediction on the reals as disc_real_pred\n","        \n","        #### START CODE HERE ####\n","        fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n","        real_image_and_labels = combine_vectors(real, image_one_hot_labels)\n","\n","        disc_fake_pred = disc(fake_image_and_labels.detach())\n","        disc_real_pred = disc(real_image_and_labels)\n","        #### END CODE HERE ####\n","        \n","        # Make sure shapes are correct \n","        assert tuple(fake_image_and_labels.shape) == (len(real), fake.detach().shape[1] + image_one_hot_labels.shape[1], image_resize ,image_resize)\n","        assert tuple(real_image_and_labels.shape) == (len(real), real.shape[1] + image_one_hot_labels.shape[1],image_resize , image_resize)\n","        # Make sure that enough predictions were made\n","        assert len(disc_real_pred) == len(real)\n","        # Make sure that the inputs are different\n","        assert torch.any(fake_image_and_labels != real_image_and_labels)\n","        # Shapes must match\n","        assert tuple(fake_image_and_labels.shape) == tuple(real_image_and_labels.shape)\n","        assert tuple(disc_fake_pred.shape) == tuple(disc_real_pred.shape)\n","        \n","        \n","        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n","        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n","        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n","        disc_loss.backward(retain_graph=True)\n","        disc_opt.step() \n","\n","        # Keep track of the average discriminator loss\n","        discriminator_losses += [disc_loss.item()]\n","\n","        ### Update generator ###\n","        # Zero out the generator gradients\n","        gen_opt.zero_grad()\n","\n","        fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n","        # This will error if you didn't concatenate your labels to your image correctly\n","        disc_fake_pred = disc(fake_image_and_labels)\n","        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n","        gen_loss.backward()\n","        gen_opt.step()\n","\n","        # Keep track of the generator losses\n","        generator_losses += [gen_loss.item()]\n","        #\n","\n","        if cur_step % display_step == 0 and cur_step > 0:\n","            gen_mean = sum(generator_losses[-display_step:]) / display_step\n","            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n","            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n","            show_tensor_images(fake)\n","            show_tensor_images(real)\n","            step_bins = 20\n","            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n","            num_examples = (len(generator_losses) // step_bins) * step_bins\n","            plt.plot(\n","                range(num_examples // step_bins), \n","                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n","                label=\"Generator Loss\"\n","            )\n","            plt.plot(\n","                range(num_examples // step_bins), \n","                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n","                label=\"Discriminator Loss\"\n","            )\n","            plt.legend()\n","            plt.show()\n","        elif cur_step == 0:\n","            print(\"Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!\")\n","        cur_step += 1"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaKpZHBgPHp9","executionInfo":{"status":"ok","timestamp":1614374810376,"user_tz":480,"elapsed":315,"user":{"displayName":"Shreya Singh","photoUrl":"","userId":"00059687442786644606"}},"outputId":"bc4c9a76-15df-47f9-c4e5-9ccfddc06f93"},"source":["fake_image_and_labels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 3312, 10, 10])"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"POfhf2o1_m2G"},"source":[""],"execution_count":null,"outputs":[]}]}